{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb16f0f",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd6157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, chi2_contingency, norm # For statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d731e1d0",
   "metadata": {},
   "source": [
    "## Import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c708bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_10340\\3836203650.py:1: DtypeWarning: Columns (38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/processed/MachineLearningRating_clean.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed/MachineLearningRating_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc3e346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                       0\n",
       "UnderwrittenCoverID              0\n",
       "PolicyID                         0\n",
       "TransactionMonth                 0\n",
       "IsVATRegistered                  0\n",
       "Citizenship                      0\n",
       "LegalType                        0\n",
       "Title                            0\n",
       "Language                         0\n",
       "Bank                             0\n",
       "AccountType                      0\n",
       "MaritalStatus                    0\n",
       "Gender                           0\n",
       "Country                          0\n",
       "Province                         0\n",
       "PostalCode                       0\n",
       "MainCrestaZone                   0\n",
       "SubCrestaZone                    0\n",
       "ItemType                         0\n",
       "mmcode                           0\n",
       "VehicleType                      0\n",
       "RegistrationYear                 0\n",
       "make                             0\n",
       "Model                            0\n",
       "Cylinders                        0\n",
       "cubiccapacity                    0\n",
       "kilowatts                        0\n",
       "bodytype                         0\n",
       "NumberOfDoors                    0\n",
       "VehicleIntroDate                 0\n",
       "CustomValueEstimate              0\n",
       "AlarmImmobiliser                 0\n",
       "TrackingDevice                   0\n",
       "CapitalOutstanding               2\n",
       "NewVehicle                       0\n",
       "WrittenOff                       0\n",
       "Rebuilt                          0\n",
       "Converted                        0\n",
       "CrossBorder                 998848\n",
       "SumInsured                       0\n",
       "TermFrequency                    0\n",
       "CalculatedPremiumPerTerm         0\n",
       "ExcessSelected                   0\n",
       "CoverCategory                    0\n",
       "CoverType                        0\n",
       "CoverGroup                       0\n",
       "Section                          0\n",
       "Product                          0\n",
       "StatutoryClass                   0\n",
       "StatutoryRiskType                0\n",
       "TotalPremium                     0\n",
       "TotalClaims                      0\n",
       "IsValueEstimateProvided          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d09daa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.api as sms # For Z-test of proportions\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7a556b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Metrics Calculated ---\n",
      "Total Exposure (Policies): 999,546\n",
      "Total Claim Count: 2,775\n",
      "Overall Claim Frequency: 0.0028\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Suppress the UserWarning from pandas/statsmodels when running multiple tests\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Assume df is your cleaned DataFrame from Task 2 (approx. 1M rows)\n",
    "\n",
    "## ----------------------------------------------------------------------\n",
    "## 1. Metric Selection and Feature Engineering\n",
    "## ----------------------------------------------------------------------\n",
    "\n",
    "# 1.1 Create Claim Flag (Binary Target for Frequency)\n",
    "# Claim Frequency (proportion of policies with at least one claim)\n",
    "df['ClaimFlag'] = np.where(df['TotalClaims'] > 0, 1, 0)\n",
    "\n",
    "# 1.2 Create Margin\n",
    "# Margin = TotalPremium - TotalClaims\n",
    "df['Margin'] = df['TotalPremium'] - df['TotalClaims']\n",
    "\n",
    "# 1.3 Create Non-Zero Claims Dataset (For Severity Testing)\n",
    "# Claim Severity (the average amount of a claim, given a claim occurred)\n",
    "df_severity = df[df['ClaimFlag'] == 1].copy()\n",
    "\n",
    "print(\"--- Metrics Calculated ---\")\n",
    "print(f\"Total Exposure (Policies): {len(df):,.0f}\")\n",
    "print(f\"Total Claim Count: {df['ClaimFlag'].sum():,.0f}\")\n",
    "print(f\"Overall Claim Frequency: {df['ClaimFlag'].mean():.4f}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cd33412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Test: H₀: No Risk Differences Across Provinces (Frequency)]\n",
      "Chi2: 110.731, P-value: 0.00000\n",
      "Decision: Reject H₀\n",
      "\n",
      "[Test: H₀: No Risk Differences Across Provinces (Severity) - Claim Severity]\n",
      "T-stat: -1.961, P-value: 0.05046\n",
      "Decision: Fail to Reject H₀\n"
     ]
    }
   ],
   "source": [
    "## ----------------------------------------------------------------------\n",
    "## 2. Statistical Testing Execution\n",
    "## ----------------------------------------------------------------------\n",
    "\n",
    "# Dictionary to store final results for the report\n",
    "results = []\n",
    "SIGNIFICANCE_THRESHOLD = 0.05\n",
    "\n",
    "def run_chi2_test(contingency_table, hypothesis_name):\n",
    "    \"\"\"Conducts a Chi-Squared test for independence.\"\"\"\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    # Calculate the overall observed frequency for interpretation\n",
    "    group_A = contingency_table.iloc[:, 1].sum()\n",
    "    total_A = contingency_table.sum(axis=1).iloc[0]\n",
    "    \n",
    "    # Check top two groups for clear effect size\n",
    "    top_groups = contingency_table.sort_values(by=1, ascending=False).index[:2]\n",
    "    freq_A = contingency_table.loc[top_groups[0], 1] / contingency_table.loc[top_groups[0]].sum()\n",
    "    freq_B = contingency_table.loc[top_groups[1], 1] / contingency_table.loc[top_groups[1]].sum()\n",
    "\n",
    "    print(f\"\\n[Test: {hypothesis_name}]\")\n",
    "    print(f\"Chi2: {chi2:.3f}, P-value: {p_value:.5f}\")\n",
    "    \n",
    "    if p_value < SIGNIFICANCE_THRESHOLD:\n",
    "        decision = \"Reject H₀\"\n",
    "        effect = f\"Difference in Frequency between {top_groups[0]} ({freq_A:.2%}) and {top_groups[1]} ({freq_B:.2%})\"\n",
    "    else:\n",
    "        decision = \"Fail to Reject H₀\"\n",
    "        effect = \"No statistically significant difference observed.\"\n",
    "        \n",
    "    print(f\"Decision: {decision}\")\n",
    "    \n",
    "    results.append({\n",
    "        'Hypothesis': hypothesis_name, \n",
    "        'Metric': 'Claim Frequency', \n",
    "        'Test': 'Chi-Squared', \n",
    "        'P_Value': p_value, \n",
    "        'Decision': decision,\n",
    "        'Effect_Size': effect\n",
    "    })\n",
    "\n",
    "\n",
    "def run_ttest(group_A_data, group_B_data, hypothesis_name, metric_name, group_A_name, group_B_name):\n",
    "    \"\"\"Conducts a T-Test for the difference between two independent sample means.\"\"\"\n",
    "    # Only run if both groups have sufficient data\n",
    "    if len(group_A_data) < 30 or len(group_B_data) < 30:\n",
    "        print(f\"\\n[Test: {hypothesis_name} - {metric_name}] Skipping (Insufficient data).\")\n",
    "        return\n",
    "\n",
    "    # T-test (assuming unequal variance, Welch's T-test)\n",
    "    t_stat, p_value = ttest_ind(group_A_data, group_B_data, equal_var=False)\n",
    "    \n",
    "    mean_A = group_A_data.mean()\n",
    "    mean_B = group_B_data.mean()\n",
    "    \n",
    "    print(f\"\\n[Test: {hypothesis_name} - {metric_name}]\")\n",
    "    print(f\"T-stat: {t_stat:.3f}, P-value: {p_value:.5f}\")\n",
    "\n",
    "    if p_value < SIGNIFICANCE_THRESHOLD:\n",
    "        decision = \"Reject H₀\"\n",
    "        effect = f\"Mean difference of {mean_A - mean_B:.2f}. {group_A_name} Mean: {mean_A:.2f}, {group_B_name} Mean: {mean_B:.2f}\"\n",
    "    else:\n",
    "        decision = \"Fail to Reject H₀\"\n",
    "        effect = \"No statistically significant difference observed.\"\n",
    "\n",
    "    print(f\"Decision: {decision}\")\n",
    "    \n",
    "    results.append({\n",
    "        'Hypothesis': hypothesis_name, \n",
    "        'Metric': metric_name, \n",
    "        'Test': 'T-Test', \n",
    "        'P_Value': p_value, \n",
    "        'Decision': decision,\n",
    "        'Effect_Size': effect\n",
    "    })\n",
    "\n",
    "# ======================================================================\n",
    "# H₀ 1: There are no risk differences across provinces\n",
    "# ======================================================================\n",
    "\n",
    "# Frequency Test: Chi-Squared for Claim Flag vs. Province\n",
    "province_contingency = pd.crosstab(df['Province'], df['ClaimFlag'])\n",
    "run_chi2_test(province_contingency, \"H₀: No Risk Differences Across Provinces (Frequency)\")\n",
    "\n",
    "# Severity Test: T-Test (Comparing Top 2 Most Exposed Provinces)\n",
    "top_provinces = df['Province'].value_counts().nlargest(2).index\n",
    "province_A = df_severity[df_severity['Province'] == top_provinces[0]]['TotalClaims']\n",
    "province_B = df_severity[df_severity['Province'] == top_provinces[1]]['TotalClaims']\n",
    "run_ttest(province_A, province_B, \"H₀: No Risk Differences Across Provinces (Severity)\", \n",
    "          \"Claim Severity\", top_provinces[0], top_provinces[1])\n",
    "\n",
    "# ======================================================================\n",
    "# H₀ 2 & 3: Risk and Margin differences between zip codes\n",
    "# ======================================================================\n",
    "# Strategy: Compare a High-Risk ZIP group vs. Low-Risk ZIP group\n",
    "\n",
    "# 1. Calculate Loss Ratio (LR) per ZIP Code\n",
    "zip_metrics = df.groupby('PostalCode').agg(\n",
    "    TotalPremium=('TotalPremium', 'sum'),\n",
    "    TotalClaims=('TotalClaims', 'sum'),\n",
    "    Exposure=('ClaimFlag', 'size')\n",
    ").reset_index()\n",
    "\n",
    "# Filter Zips with very low exposure for stable calculation\n",
    "zip_metrics = zip_metrics[zip_metrics['Exposure'] >= 100] # Adjust threshold as needed\n",
    "zip_metrics['LossRatio'] = zip_metrics['TotalClaims'] / zip_metrics['TotalPremium']\n",
    "\n",
    "# 2. Define High-Risk (Top 10% LR) and Low-Risk (Bottom 10% LR) ZIP Groups\n",
    "lr_threshold_high = zip_metrics['LossRatio'].quantile(0.90)\n",
    "lr_threshold_low = zip_metrics['LossRatio'].quantile(0.10)\n",
    "\n",
    "high_risk_zips = zip_metrics[zip_metrics['LossRatio'] >= lr_threshold_high]['PostalCode']\n",
    "low_risk_zips = zip_metrics[zip_metrics['LossRatio'] <= lr_threshold_low]['PostalCode']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "761f1422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "Not specified    940438\n",
      "Male              42817\n",
      "Unknown            9536\n",
      "Female             6755\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the actual values in the Gender column\n",
    "print(df['Gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c8969a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Test: H₀: No Risk Differences Between Postal Code Groups (Frequency)]\n",
      "Chi2: 447.603, P-value: 0.00000\n",
      "Decision: Reject H₀\n",
      "\n",
      "[Test: H₀: No Significant Margin Difference Between Postal Code Groups - Margin (Total Premium - Total Claims)]\n",
      "T-stat: -9.856, P-value: 0.00000\n",
      "Decision: Reject H₀\n",
      "\n",
      "[Test: H₀: No Significant Risk Difference Between Women and Men (Frequency)]\n",
      "Chi2: 0.004, P-value: 0.95146\n",
      "Decision: Fail to Reject H₀\n",
      "\n",
      "[Test: H₀: No Significant Risk Difference Between Women and Men (Severity) - Claim Severity] Skipping (Insufficient data).\n"
     ]
    }
   ],
   "source": [
    "# 3. Create Samples for Testing\n",
    "high_risk_sample = df[df['PostalCode'].isin(high_risk_zips)]\n",
    "low_risk_sample = df[df['PostalCode'].isin(low_risk_zips)]\n",
    "\n",
    "# H₀ 2: No risk difference (Frequency) between High/Low LR Postals\n",
    "Postal_contingency = pd.crosstab(\n",
    "    np.where(df['PostalCode'].isin(high_risk_zips), 'High_Risk_Postal', \n",
    "             np.where(df['PostalCode'].isin(low_risk_zips), 'Low_Risk_Postal', 'Other')),\n",
    "    df['ClaimFlag']\n",
    ").iloc[0:2, :] # Select only the two test groups\n",
    "run_chi2_test(Postal_contingency, \"H₀: No Risk Differences Between Postal Code Groups (Frequency)\")\n",
    "\n",
    "\n",
    "# H₀ 3: No significant margin difference between Postal codes (T-Test on Margin)\n",
    "run_ttest(high_risk_sample['Margin'], low_risk_sample['Margin'], \n",
    "          \"H₀: No Significant Margin Difference Between Postal Code Groups\", \n",
    "          \"Margin (Total Premium - Total Claims)\", \"High_Risk_Postal_Group\", \"Low_Risk_Postal_Group\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# H₀ 4: There is no significant risk difference between Women and Men\n",
    "# ======================================================================\n",
    "# Filter to only known genders\n",
    "df_gender = df[df['Gender'].isin(['Female', 'Male'])].copy()\n",
    "\n",
    "# Frequency Test: Chi-Squared for Claim Flag vs. Gender\n",
    "gender_contingency = pd.crosstab(df_gender['Gender'], df_gender['ClaimFlag'])\n",
    "run_chi2_test(gender_contingency, \"H₀: No Significant Risk Difference Between Women and Men (Frequency)\")\n",
    "\n",
    "# Severity Test: T-Test\n",
    "men_claims = df_severity[df_severity['Gender'] == 'Male']['TotalClaims']\n",
    "women_claims = df_severity[df_severity['Gender'] == 'Female']['TotalClaims']\n",
    "run_ttest(women_claims, men_claims, \"H₀: No Significant Risk Difference Between Women and Men (Severity)\", \n",
    "          \"Claim Severity\", \"Women\", \"Men\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecbc3fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================================================================\n",
      "FINAL HYPOTHESIS TESTING SUMMARY\n",
      "======================================================================\n",
      "| Hypothesis                                                           | Metric                                | Decision          |   P_Value | Effect_Size                                                                                         | Interpretation                   |\n",
      "|:---------------------------------------------------------------------|:--------------------------------------|:------------------|----------:|:----------------------------------------------------------------------------------------------------|:---------------------------------|\n",
      "| H₀: No Risk Differences Across Provinces (Frequency)                 | Claim Frequency                       | Reject H₀         |   0       | Difference in Frequency between Gauteng (0.34%) and KwaZulu-Natal (0.28%)                           | Statistically Significant Effect |\n",
      "| H₀: No Risk Differences Across Provinces (Severity)                  | Claim Severity                        | Fail to Reject H₀ |   0.05046 | No statistically significant difference observed.                                                   | No Significant Effect Found      |\n",
      "| H₀: No Risk Differences Between Postal Code Groups (Frequency)       | Claim Frequency                       | Reject H₀         |   0       | Difference in Frequency between High_Risk_Postal (0.53%) and Low_Risk_Postal (0.00%)                | Statistically Significant Effect |\n",
      "| H₀: No Significant Margin Difference Between Postal Code Groups      | Margin (Total Premium - Total Claims) | Reject H₀         |   0       | Mean difference of -229.62. High_Risk_Postal_Group Mean: -169.52, Low_Risk_Postal_Group Mean: 60.11 | Statistically Significant Effect |\n",
      "| H₀: No Risk Differences Between Postal Code Groups (Frequency)       | Claim Frequency                       | Reject H₀         |   0       | Difference in Frequency between High_Risk_Postal (0.53%) and Low_Risk_Postal (0.00%)                | Statistically Significant Effect |\n",
      "| H₀: No Significant Margin Difference Between Postal Code Groups      | Margin (Total Premium - Total Claims) | Reject H₀         |   0       | Mean difference of -229.62. High_Risk_Postal_Group Mean: -169.52, Low_Risk_Postal_Group Mean: 60.11 | Statistically Significant Effect |\n",
      "| H₀: No Significant Risk Difference Between Women and Men (Frequency) | Claim Frequency                       | Fail to Reject H₀ |   0.95146 | No statistically significant difference observed.                                                   | No Significant Effect Found      |\n",
      "\n",
      "--- BUSINESS RECOMMENDATIONS ---\n",
      "\n",
      "✅ Hypothesis: H₀: No Risk Differences Across Provinces (Frequency) (Claim Frequency)\n",
      "Interpretation: We reject the null hypothesis (P < 0.05). The factor is a significant risk driver.\n",
      "Recommendation: Incorporate the factor into the pricing model and segmentation strategy.\n",
      "\n",
      "Hypothesis: H₀: No Risk Differences Across Provinces (Severity) (Claim Severity)\n",
      "Interpretation: We fail to reject the null hypothesis (P >= 0.05). The factor is NOT a significant risk driver.\n",
      "Recommendation: Do not use this factor for segmentation or risk adjustment in the pricing model.\n",
      "\n",
      "✅ Hypothesis: H₀: No Risk Differences Between Postal Code Groups (Frequency) (Claim Frequency)\n",
      "Interpretation: We reject the null hypothesis (P < 0.05). The factor is a significant risk driver.\n",
      "Recommendation: Incorporate the factor into the pricing model and segmentation strategy.\n",
      "\n",
      "✅ Hypothesis: H₀: No Significant Margin Difference Between Postal Code Groups (Margin (Total Premium - Total Claims))\n",
      "Interpretation: We reject the null hypothesis (P < 0.05). The factor is a significant risk driver.\n",
      "Recommendation: Incorporate the factor into the pricing model and segmentation strategy.\n",
      "\n",
      "✅ Hypothesis: H₀: No Risk Differences Between Postal Code Groups (Frequency) (Claim Frequency)\n",
      "Interpretation: We reject the null hypothesis (P < 0.05). The factor is a significant risk driver.\n",
      "Recommendation: Incorporate the factor into the pricing model and segmentation strategy.\n",
      "\n",
      "✅ Hypothesis: H₀: No Significant Margin Difference Between Postal Code Groups (Margin (Total Premium - Total Claims))\n",
      "Interpretation: We reject the null hypothesis (P < 0.05). The factor is a significant risk driver.\n",
      "Recommendation: Incorporate the factor into the pricing model and segmentation strategy.\n",
      "\n",
      "Hypothesis: H₀: No Significant Risk Difference Between Women and Men (Frequency) (Claim Frequency)\n",
      "Interpretation: We fail to reject the null hypothesis (P >= 0.05). The factor is NOT a significant risk driver.\n",
      "Recommendation: Do not use this factor for segmentation or risk adjustment in the pricing model.\n"
     ]
    }
   ],
   "source": [
    "## ----------------------------------------------------------------------\n",
    "## 3. Analyze and Report (Final Summary)\n",
    "## ----------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*70)\n",
    "print(\"FINAL HYPOTHESIS TESTING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary_df = pd.DataFrame(results)\n",
    "\n",
    "# Clean up and present the P-Value\n",
    "summary_df['P_Value'] = summary_df['P_Value'].apply(lambda x: f\"{x:.5f}\")\n",
    "summary_df['Interpretation'] = np.where(summary_df['Decision'] == 'Reject H₀', \n",
    "                                       'Statistically Significant Effect', \n",
    "                                       'No Significant Effect Found')\n",
    "\n",
    "print(summary_df[['Hypothesis', 'Metric', 'Decision', 'P_Value', 'Effect_Size', 'Interpretation']].to_markdown(index=False))\n",
    "\n",
    "# --- BUSINESS RECOMMENDATIONS (Based on typical outcomes) ---\n",
    "print(\"\\n--- BUSINESS RECOMMENDATIONS ---\")\n",
    "for index, row in summary_df.iterrows():\n",
    "    if row['Decision'] == 'Reject H₀':\n",
    "        print(f\"\\n✅ Hypothesis: {row['Hypothesis']} ({row['Metric']})\")\n",
    "        print(f\"Interpretation: We reject the null hypothesis (P < {SIGNIFICANCE_THRESHOLD}). The factor is a significant risk driver.\")\n",
    "        print(f\"Recommendation: Incorporate the factor into the pricing model and segmentation strategy.\")\n",
    "    else:\n",
    "        print(f\"\\nHypothesis: {row['Hypothesis']} ({row['Metric']})\")\n",
    "        print(f\"Interpretation: We fail to reject the null hypothesis (P >= {SIGNIFICANCE_THRESHOLD}). The factor is NOT a significant risk driver.\")\n",
    "        print(f\"Recommendation: Do not use this factor for segmentation or risk adjustment in the pricing model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
